[model]
type = "QD3DT"
    [model.detection]
    type = "MMTwoStageDetector"
    model_base = "mmdet://_base_/models/faster_rcnn_r50_fpn.py"
    model_kwargs = {"rpn_head.anchor_generator.scales" = [4, 8], "rpn_head.anchor_generator.ratios" = [0.25, 0.5, 1.0, 2.0, 4.0], "rpn_head.loss_bbox.type" = "SmoothL1Loss", "rpn_head.loss_bbox.beta" = 0.111, "roi_head.bbox_head.type" = "ConvFCBBoxHead", "roi_head.bbox_head.num_shared_convs" = 4, "roi_head.bbox_head.num_shared_fcs" = 2, "roi_head.bbox_head.loss_cls.loss_weight" = 5.0, "roi_head.bbox_head.loss_bbox.type" = "SmoothL1Loss", "roi_head.bbox_head.loss_bbox.beta" = 0.111, "roi_head.bbox_head.loss_bbox.loss_weight" = 5.0}
    pixel_mean = [123.675, 116.28, 103.53]
    pixel_std = [58.395, 57.12, 57.375]
    backbone_output_names = ["p2", "p3", "p4", "p5", "p6"]

    [model.bbox_3d_head]
    type = "QD3DTBBox3DHead"
    in_channels = 256
    fc_out_dim = 1024
    roi_feat_size = 7
    proposal_append_gt = true

        [model.bbox_3d_head.loss]
        type = 'Box3DUncertaintyLoss'
        loss_weights = [1.0, 1.0, 1.0, 1.0, 1.0]

        [model.bbox_3d_head.proposal_pooler]
        type = "MultiScaleRoIAlign"
        resolution = [7, 7]
        strides = [4, 8, 16, 32]
        sampling_ratio = 0

        [model.bbox_3d_head.proposal_sampler]
        type = "CombinedSampler"
        batch_size_per_image = 512
        positive_fraction = 0.25
        pos_strategy = "instance_balanced"
        neg_strategy = "iou_balanced"

        [model.bbox_3d_head.proposal_matcher]
        type = "MaxIoUMatcher"
        thresholds = [0.5, 0.5]
        labels = [0, -1, 1]
        allow_low_quality_matches = false

        [model.bbox_3d_head.box3d_coder]
        type = "QD3DTBox3DCoder"
        center_scale = 10.0
        depth_log_scale = 2.0
        dim_log_scale = 2.0

    [model.track_graph]
    type = "QD3DTrackGraph"
    keep_in_memory = 10  # timesteps
    init_score_thr = 0.8
    obj_score_thr = 0.5

    [model.track_graph.motion_model]
        type = "LSTM3DMotionModel"
        motion_dims = 7
        num_frames = 5
        lstm_name = "VeloLSTM"
        lstm_ckpt_name = "vis4d-workspace/checkpoints/batch128_min10_seq10_dim7_VeloLSTM_nuscenes_100_linear.pth"
        feature_dim = 64
        hidden_size = 128
        num_layers = 2

    [model.similarity]
    type = "QDSimilarityHead"
    in_dim = 256
    num_convs = 4
    conv_out_dim = 256
    num_fcs = 1
    fc_out_dim = 1024
    embedding_dim = 256
    conv_has_bias = false
    norm = "GroupNorm"
    proposal_append_gt = true

        [model.similarity.track_loss]
        type = "MultiPosCrossEntropyLoss"
        loss_weight = 0.25

        [model.similarity.track_loss_aux]
        type = "EmbeddingDistanceLoss"
        loss_weight = 1.0
        neg_pos_ub = 3
        pos_margin = 0
        neg_margin = 0.3
        hard_mining = true

        [model.similarity.proposal_pooler]
        type = "MultiScaleRoIAlign"
        resolution = [7, 7]
        strides = [4, 8, 16, 32]
        sampling_ratio = 0

        [model.similarity.proposal_sampler]
        type = "CombinedSampler"
        batch_size_per_image = 256
        positive_fraction = 0.5
        pos_strategy = "instance_balanced"
        neg_strategy = "iou_balanced"

        [model.similarity.proposal_matcher]
        type = "MaxIoUMatcher"
        thresholds = [0.3, 0.7]
        labels = [0, -1, 1]
        allow_low_quality_matches = false
