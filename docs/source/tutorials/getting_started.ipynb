{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "This notebook illustrates the basic usage of Vis4D. We will visualize a COCO image with detections from Faster RCNN.\n",
    "\n",
    "First, import the necessary components from the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/tobfischer/net_scratch/conda_envs/vis4d-dev/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from vis4d.model.detect.faster_rcnn import FasterRCNN\n",
    "\n",
    "from vis4d.run.data.detect import default_test_pipeline\n",
    "from vis4d.data.datasets.coco import COCO\n",
    "from vis4d.data.const import CommonKeys\n",
    "from vis4d.vis.functional import imshow_bboxes\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/tobfischer/PycharmProjects/vist/dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the dataset and fetch the image from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading COCODataset(root=tests/test_data/coco_test/, split=train, use_pascal_voc_cats=False) takes 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = COCO(\"tests/test_data/coco_test/\", split=\"train\")\n",
    "test_dataloader = default_test_pipeline(dataset, 1, 1, (800, 1333))[0]\n",
    "batch = next(iter(test_dataloader))\n",
    "inputs, images_hw = (\n",
    "    batch[CommonKeys.images],\n",
    "    batch[CommonKeys.input_hw],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can initialize and run the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/tobfischer/net_scratch/conda_envs/vis4d-dev/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/itet-stor/tobfischer/net_scratch/conda_envs/vis4d-dev/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "faster_rcnn = FasterRCNN(num_classes=80, weights=\"mmdet\")\n",
    "\n",
    "faster_rcnn.eval()\n",
    "dets = faster_rcnn(inputs, images_hw, original_hw=images_hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "min() received an invalid combination of arguments - got (out=NoneType, axis=tuple, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imshow_bboxes(inputs[\u001b[39m0\u001b[39;49m], dets[\u001b[39m\"\u001b[39;49m\u001b[39mboxes2d\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m], dets[\u001b[39m\"\u001b[39;49m\u001b[39mboxes2d_scores\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m], dets[\u001b[39m\"\u001b[39;49m\u001b[39mboxes2d_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/PycharmProjects/vist/dev/vis4d/vis/functional.py:153\u001b[0m, in \u001b[0;36mimshow_bboxes\u001b[0;34m(image, boxes, scores, class_ids, track_ids, class_id_mapping, n_colors, image_mode, image_viewer)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow_bboxes\u001b[39m(\n\u001b[1;32m    126\u001b[0m     image: NDArrayNumber,\n\u001b[1;32m    127\u001b[0m     boxes: NDArrayF64,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     image_viewer: ImageViewerBackend \u001b[39m=\u001b[39m MatplotlibImageViewer(),\n\u001b[1;32m    135\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39m\"\"\"Shows the bounding boxes overlayed on the given image.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m            to use. Defaults to MatplotlibImageViewer().\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     image \u001b[39m=\u001b[39m preprocess_image(image, mode\u001b[39m=\u001b[39;49mimage_mode)\n\u001b[1;32m    154\u001b[0m     img \u001b[39m=\u001b[39m draw_bboxes(\n\u001b[1;32m    155\u001b[0m         image,\n\u001b[1;32m    156\u001b[0m         boxes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         image_mode,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     imshow(img, image_viewer)\n",
      "File \u001b[0;32m~/PycharmProjects/vist/dev/vis4d/vis/image/util.py:173\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image, mode)\u001b[0m\n\u001b[1;32m    170\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[39m# Convert image to [0, 255]\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m min_val, max_val \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39;49mmin(image, axis\u001b[39m=\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)), np\u001b[39m.\u001b[39mmax(image, axis\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)))\n\u001b[1;32m    174\u001b[0m image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    175\u001b[0m image \u001b[39m=\u001b[39m (image \u001b[39m-\u001b[39m min_val) \u001b[39m/\u001b[39m (max_val \u001b[39m-\u001b[39m min_val) \u001b[39m*\u001b[39m \u001b[39m255.0\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/itet-stor/tobfischer/net_scratch/conda_envs/vis4d-dev/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2918\u001b[0m, in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[1;32m   2803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2804\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2805\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2806\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2807\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2916\u001b[0m \u001b[39m    6\u001b[39;00m\n\u001b[1;32m   2917\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2918\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mminimum, \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2919\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/itet-stor/tobfischer/net_scratch/conda_envs/vis4d-dev/lib/python3.10/site-packages/numpy/core/fromnumeric.py:84\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: min() received an invalid combination of arguments - got (out=NoneType, axis=tuple, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n"
     ]
    }
   ],
   "source": [
    "imshow_bboxes(inputs[0], dets[\"boxes2d\"][0], dets[\"boxes2d_scores\"][0], dets[\"boxes2d_classes\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('vis4d-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "493a28f476a783d7b2a9d9b1c7c6a124417e250d1a603c3e37d189d1e159ab15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
